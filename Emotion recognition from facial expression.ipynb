{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Convolution2D, MaxPooling2D\n",
    "from keras.optimizers import Adadelta\n",
    "from keras.utils import np_utils\n",
    "from keras.regularizers import l2  #, activity_l2\n",
    "import numpy\n",
    "import csv\n",
    "import scipy.misc\n",
    "import scipy\n",
    "from scipy import ndimage\n",
    "import imutils\n",
    "import cv2\n",
    "import numpy as np\n",
    "import imageio\n",
    "from PIL import Image\n",
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten_matrix(matrix):\n",
    "    vector = matrix.flatten(1)\n",
    "    vector = vector.reshape(1, len(vector))\n",
    "    return vector\n",
    "\n",
    "def zca_whitening(inputs):\n",
    "    sigma = np.dot(inputs, inputs.T)/inputs.shape[1] #Correlation matrix\n",
    "    U,S,V = np.linalg.svd(sigma) #Singular Value Decomposition\n",
    "    epsilon = 0.1                #Whitening constant, it prevents division by zero\n",
    "    ZCAMatrix = np.dot(np.dot(U, np.diag(1.0/np.sqrt(np.diag(S) + epsilon))), U.T)                     #ZCA Whitening matrix\n",
    "    return np.dot(ZCAMatrix, inputs)   #Data whitening\n",
    "    \n",
    "def global_contrast_normalize(X, scale=1., subtract_mean=True, use_std=True,\n",
    "                              sqrt_bias=10, min_divisor=1e-8):\n",
    "\n",
    "    assert X.ndim == 2, \"X.ndim must be 2\"\n",
    "    scale = float(scale)\n",
    "    assert scale >= min_divisor\n",
    "\n",
    "    mean = X.mean(axis=1)\n",
    "    if subtract_mean:\n",
    "        X = X - mean[:, numpy.newaxis]  \n",
    "    else:\n",
    "        X = X.copy()\n",
    "    if use_std:\n",
    "        ddof = 1\n",
    "        if X.shape[1] == 1:\n",
    "            ddof = 0\n",
    "        normalizers = numpy.sqrt(sqrt_bias + X.var(axis=1, ddof=ddof)) / scale\n",
    "    else:\n",
    "        normalizers = numpy.sqrt(sqrt_bias + (X ** 2).sum(axis=1)) / scale\n",
    "    normalizers[normalizers < min_divisor] = 1.\n",
    "    X /= normalizers[:, numpy.newaxis]  # Does not make a copy.\n",
    "    return X\n",
    "def ZeroCenter(data):\n",
    "    data = data - numpy.mean(data,axis=0)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(arr):\n",
    "    for i in range(3):\n",
    "        minval = arr[...,i].min()\n",
    "        maxval = arr[...,i].max()\n",
    "        if minval != maxval:\n",
    "            arr[...,i] -= minval\n",
    "            arr[...,i] *= (255.0/(maxval-minval))\n",
    "    return arr\n",
    "\n",
    "def Flip(data):\n",
    "    dataFlipped = data[..., ::-1].reshape(2304).tolist()\n",
    "    return dataFlipped\n",
    "\n",
    "def Roated15Left(data):\n",
    "    num_rows, num_cols = data.shape[:2]\n",
    "    rotation_matrix = cv2.getRotationMatrix2D((num_cols/2, num_rows/2), 30, 1)\n",
    "    img_rotation = cv2.warpAffine(data, rotation_matrix, (num_cols, num_rows))\n",
    "    return img_rotation.reshape(2304).tolist()\n",
    "\n",
    "def Roated15Right(data):\n",
    "    num_rows, num_cols = data.shape[:2]\n",
    "    rotation_matrix = cv2.getRotationMatrix2D((num_cols/2, num_rows/2), -30, 1)\n",
    "    img_rotation = cv2.warpAffine(data, rotation_matrix, (num_cols, num_rows))\n",
    "    return img_rotation.reshape(2304).tolist()\n",
    "\n",
    "def Zoomed(data):\n",
    "    datazoomed = scipy.misc.imresize(data,(60,60))\n",
    "    datazoomed = datazoomed[5:53,5:53]\n",
    "    datazoomed = datazoomed.reshape(2304).tolist()\n",
    "    return datazoomed\n",
    "\n",
    "def shiftedUp20(data):\n",
    "    translated = imutils.translate(data, 0, -5)\n",
    "    translated2 = translated.reshape(2304).tolist()\n",
    "    return translated2\n",
    "def shiftedDown20(data):\n",
    "    translated = imutils.translate(data, 0, 5)\n",
    "    translated2 = translated.reshape(2304).tolist()\n",
    "    return translated2\n",
    "\n",
    "def shiftedLeft20(data):\n",
    "    translated = imutils.translate(data, -5, 0)\n",
    "    translated2 = translated.reshape(2304).tolist()\n",
    "    return translated2\n",
    "def shiftedRight20(data):\n",
    "    translated = imutils.translate(data, 5, 0)\n",
    "    translated2 = translated.reshape(2304).tolist()\n",
    "    return translated2\n",
    "\n",
    "def outputImage(pixels,number):\n",
    "    data = pixels\n",
    "    name = str(number)+\"output.jpg\" \n",
    "    scipy.misc.imsave(name, data)\n",
    "\n",
    "def Zerocenter_ZCA_whitening_Global_Contrast_Normalize(list):\n",
    "    Intonumpyarray = numpy.asarray(list)\n",
    "    data = Intonumpyarray.reshape(48,48)\n",
    "    data2 = ZeroCenter(data)\n",
    "    data3 = zca_whitening(flatten_matrix(data2)).reshape(48,48)\n",
    "    data4 = global_contrast_normalize(data3)\n",
    "    data5 = numpy.rot90(data4,3)\n",
    "    return data5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_test_data():\n",
    "    f = open('fer2013.csv')\n",
    "    csv_f = csv.reader(f)\n",
    "    test_set_x =[]\n",
    "    test_set_y =[]\n",
    "    for row in csv_f:  \n",
    "        if str(row[2]) == \"PrivateTest\" :\n",
    "            test_set_y.append(int(row[0]))\n",
    "            temp_list = []\n",
    "            for pixel in row[1].split( ):\n",
    "                temp_list.append(int(pixel))\n",
    "            data = Zerocenter_ZCA_whitening_Global_Contrast_Normalize(temp_list)\n",
    "            test_set_x.append(data)\n",
    "    return test_set_x, test_set_y\n",
    "\n",
    "def load_data():\n",
    "\n",
    "    train_x = []\n",
    "    train_y = []\n",
    "    val_x =[]\n",
    "    val_y =[]\n",
    "\n",
    "    with open(\"badtrainingdata.txt\", \"r\") as text:\n",
    "        ToBeRemovedTrainingData = []\n",
    "        for line in text:\n",
    "            ToBeRemovedTrainingData.append(int(line))\n",
    "    number = 0\n",
    "\n",
    "    f = open('fer2013.csv')\n",
    "    csv_f = csv.reader(f)\n",
    "\n",
    "    for row in csv_f:   \n",
    "        number+= 1\n",
    "        if number not in ToBeRemovedTrainingData:\n",
    "\n",
    "            if str(row[2]) == \"Training\" or str(row[2]) == \"PublicTest\" :\n",
    "                temp_list = []\n",
    "\n",
    "                for pixel in row[1].split( ):\n",
    "                    temp_list.append(int(pixel))\n",
    "\n",
    "                data = Zerocenter_ZCA_whitening_Global_Contrast_Normalize(temp_list)\n",
    "                train_y.append(int(row[0]))\n",
    "                train_x.append(data.reshape(2304).tolist())\n",
    "\n",
    "            elif str(row[2]) == \"PrivateTest\":\n",
    "                temp_list = []\n",
    "                for pixel in row[1].split( ):\n",
    "                    temp_list.append(int(pixel))\n",
    "\n",
    "                data = Zerocenter_ZCA_whitening_Global_Contrast_Normalize(temp_list)\n",
    "                val_y.append(int(row[0]))\n",
    "                val_x.append(data.reshape(2304).tolist())\n",
    "\n",
    "    return train_x, train_y, val_x, val_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_generate():\n",
    "    img_rows, img_cols = 48, 48\n",
    "    model = Sequential()\n",
    "    model.add(Convolution2D(64, 5, 5, border_mode='valid',\n",
    "                            input_shape=(img_rows, img_cols,1)))\n",
    "    model.add(keras.layers.advanced_activations.PReLU(init='zero', weights=None))\n",
    "    model.add(keras.layers.convolutional.ZeroPadding2D(padding=(2, 2), dim_ordering='tf'))\n",
    "    model.add(MaxPooling2D(pool_size=(5, 5),strides=(2, 2)))\n",
    "      \n",
    "    model.add(keras.layers.convolutional.ZeroPadding2D(padding=(1, 1), dim_ordering='tf')) \n",
    "    model.add(Convolution2D(64, 3, 3))\n",
    "    model.add(keras.layers.advanced_activations.PReLU(init='zero', weights=None))\n",
    "    model.add(keras.layers.convolutional.ZeroPadding2D(padding=(1, 1), dim_ordering='tf')) \n",
    "    model.add(Convolution2D(64, 3, 3))\n",
    "    model.add(keras.layers.advanced_activations.PReLU(init='zero', weights=None))\n",
    "    model.add(keras.layers.convolutional.AveragePooling2D(pool_size=(3, 3),strides=(2, 2)))\n",
    "     \n",
    "    model.add(keras.layers.convolutional.ZeroPadding2D(padding=(1, 1), dim_ordering='tf'))\n",
    "    model.add(Convolution2D(128, 3, 3))\n",
    "    model.add(keras.layers.advanced_activations.PReLU(init='zero', weights=None))\n",
    "    model.add(keras.layers.convolutional.ZeroPadding2D(padding=(1, 1), dim_ordering='tf'))\n",
    "    model.add(Convolution2D(128, 3, 3))\n",
    "    model.add(keras.layers.advanced_activations.PReLU(init='zero', weights=None))\n",
    "     \n",
    "    model.add(keras.layers.convolutional.ZeroPadding2D(padding=(1, 1), dim_ordering='tf'))\n",
    "    model.add(keras.layers.convolutional.AveragePooling2D(pool_size=(3, 3),strides=(2, 2)))\n",
    "     \n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(1024))\n",
    "    model.add(keras.layers.advanced_activations.PReLU(init='zero', weights=None))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(1024))\n",
    "    model.add(keras.layers.advanced_activations.PReLU(init='zero', weights=None))\n",
    "    model.add(Dropout(0.2))\n",
    "     \n",
    "      \n",
    "    model.add(Dense(7))\n",
    "      \n",
    "      \n",
    "    model.add(Activation('softmax'))\n",
    "\n",
    "    ada = Adadelta(lr=0.1, rho=0.95, epsilon=1e-08)\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer=ada,\n",
    "                  metrics=['accuracy'])\n",
    "    model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_rows, img_cols = 48, 48\n",
    "batch_size = 128\n",
    "nb_classes = 7\n",
    "nb_epoch = 600\n",
    "img_channels = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: DeprecationWarning: Non-string object detected for the array ordering. Please pass in 'C', 'F', 'A', or 'K' instead\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "Train_x, Train_y, Val_x, Val_y = load_data()\n",
    "\n",
    "Train_x = numpy.asarray(Train_x) \n",
    "Train_x = Train_x.reshape(Train_x.shape[0],img_rows,img_cols)\n",
    "\n",
    "Val_x = numpy.asarray(Val_x)\n",
    "Val_x = Val_x.reshape(Val_x.shape[0],img_rows,img_cols)\n",
    "\n",
    "Train_x = Train_x.reshape(Train_x.shape[0], img_rows, img_cols,1)\n",
    "Val_x = Val_x.reshape(Val_x.shape[0], img_rows, img_cols,1)\n",
    "\n",
    "Train_x = Train_x.astype('float32')\n",
    "Val_x = Val_x.astype('float32')\n",
    "\n",
    "\n",
    "Train_y = np_utils.to_categorical(Train_y, nb_classes)\n",
    "Val_y = np_utils.to_categorical(Val_y, nb_classes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (5, 5), input_shape=(48, 48, 1..., padding=\"valid\")`\n",
      "  \"\"\"\n",
      "C:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:6: UserWarning: Update your `PReLU` call to the Keras 2 API: `PReLU(weights=None, alpha_initializer=\"zero\")`\n",
      "  \n",
      "C:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: Update your `ZeroPadding2D` call to the Keras 2 API: `ZeroPadding2D(padding=(2, 2), data_format=\"channels_last\")`\n",
      "  import sys\n",
      "C:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:10: UserWarning: Update your `ZeroPadding2D` call to the Keras 2 API: `ZeroPadding2D(padding=(1, 1), data_format=\"channels_last\")`\n",
      "  # Remove the CWD from sys.path while we load stuff.\n",
      "C:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:11: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (3, 3))`\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "C:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:12: UserWarning: Update your `PReLU` call to the Keras 2 API: `PReLU(weights=None, alpha_initializer=\"zero\")`\n",
      "  if sys.path[0] == '':\n",
      "C:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:13: UserWarning: Update your `ZeroPadding2D` call to the Keras 2 API: `ZeroPadding2D(padding=(1, 1), data_format=\"channels_last\")`\n",
      "  del sys.path[0]\n",
      "C:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:14: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (3, 3))`\n",
      "  \n",
      "C:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:15: UserWarning: Update your `PReLU` call to the Keras 2 API: `PReLU(weights=None, alpha_initializer=\"zero\")`\n",
      "  from ipykernel import kernelapp as app\n",
      "C:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:18: UserWarning: Update your `ZeroPadding2D` call to the Keras 2 API: `ZeroPadding2D(padding=(1, 1), data_format=\"channels_last\")`\n",
      "C:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:19: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (3, 3))`\n",
      "C:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:20: UserWarning: Update your `PReLU` call to the Keras 2 API: `PReLU(weights=None, alpha_initializer=\"zero\")`\n",
      "C:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:21: UserWarning: Update your `ZeroPadding2D` call to the Keras 2 API: `ZeroPadding2D(padding=(1, 1), data_format=\"channels_last\")`\n",
      "C:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:22: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (3, 3))`\n",
      "C:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:23: UserWarning: Update your `PReLU` call to the Keras 2 API: `PReLU(weights=None, alpha_initializer=\"zero\")`\n",
      "C:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:25: UserWarning: Update your `ZeroPadding2D` call to the Keras 2 API: `ZeroPadding2D(padding=(1, 1), data_format=\"channels_last\")`\n",
      "C:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:30: UserWarning: Update your `PReLU` call to the Keras 2 API: `PReLU(weights=None, alpha_initializer=\"zero\")`\n",
      "C:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:33: UserWarning: Update your `PReLU` call to the Keras 2 API: `PReLU(weights=None, alpha_initializer=\"zero\")`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_6 (Conv2D)            (None, 44, 44, 64)        1664      \n",
      "_________________________________________________________________\n",
      "p_re_lu_8 (PReLU)            (None, 44, 44, 64)        123904    \n",
      "_________________________________________________________________\n",
      "zero_padding2d_7 (ZeroPaddin (None, 48, 48, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 22, 22, 64)        0         \n",
      "_________________________________________________________________\n",
      "zero_padding2d_8 (ZeroPaddin (None, 24, 24, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 22, 22, 64)        36928     \n",
      "_________________________________________________________________\n",
      "p_re_lu_9 (PReLU)            (None, 22, 22, 64)        30976     \n",
      "_________________________________________________________________\n",
      "zero_padding2d_9 (ZeroPaddin (None, 24, 24, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 22, 22, 64)        36928     \n",
      "_________________________________________________________________\n",
      "p_re_lu_10 (PReLU)           (None, 22, 22, 64)        30976     \n",
      "_________________________________________________________________\n",
      "average_pooling2d_3 (Average (None, 10, 10, 64)        0         \n",
      "_________________________________________________________________\n",
      "zero_padding2d_10 (ZeroPaddi (None, 12, 12, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 10, 10, 128)       73856     \n",
      "_________________________________________________________________\n",
      "p_re_lu_11 (PReLU)           (None, 10, 10, 128)       12800     \n",
      "_________________________________________________________________\n",
      "zero_padding2d_11 (ZeroPaddi (None, 12, 12, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 10, 10, 128)       147584    \n",
      "_________________________________________________________________\n",
      "p_re_lu_12 (PReLU)           (None, 10, 10, 128)       12800     \n",
      "_________________________________________________________________\n",
      "zero_padding2d_12 (ZeroPaddi (None, 12, 12, 128)       0         \n",
      "_________________________________________________________________\n",
      "average_pooling2d_4 (Average (None, 5, 5, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 3200)              0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1024)              3277824   \n",
      "_________________________________________________________________\n",
      "p_re_lu_13 (PReLU)           (None, 1024)              1024      \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1024)              1049600   \n",
      "_________________________________________________________________\n",
      "p_re_lu_14 (PReLU)           (None, 1024)              1024      \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 7)                 7175      \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 7)                 0         \n",
      "=================================================================\n",
      "Total params: 4,845,063\n",
      "Trainable params: 4,845,063\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:25: UserWarning: The semantics of the Keras 2 argument `steps_per_epoch` is not the same as the Keras 1 argument `samples_per_epoch`. `steps_per_epoch` is the number of batches to draw from the generator at each epoch. Basically steps_per_epoch = samples_per_epoch/batch_size. Similarly `nb_val_samples`->`validation_steps` and `val_samples`->`steps` arguments have changed. Update your method calls accordingly.\n",
      "C:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:25: UserWarning: Update your `fit_generator` call to the Keras 2 API: `fit_generator(<keras_pre..., validation_data=(array([[[..., callbacks=[<keras.ca..., steps_per_epoch=251, epochs=600)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/600\n",
      "251/251 [==============================] - 691s 3s/step - loss: 1.8274 - acc: 0.2480 - val_loss: 1.8136 - val_acc: 0.2449\n",
      "\n",
      "Epoch 00001: saving model to Model.01-0.2449.hdf5\n",
      "Epoch 2/600\n",
      "251/251 [==============================] - 674s 3s/step - loss: 1.8104 - acc: 0.2520 - val_loss: 1.8046 - val_acc: 0.2513\n",
      "\n",
      "Epoch 00002: saving model to Model.02-0.2513.hdf5\n",
      "Epoch 3/600\n",
      "251/251 [==============================] - 677s 3s/step - loss: 1.8065 - acc: 0.2543 - val_loss: 1.7920 - val_acc: 0.2608\n",
      "\n",
      "Epoch 00003: saving model to Model.03-0.2608.hdf5\n",
      "Epoch 4/600\n",
      "251/251 [==============================] - 687s 3s/step - loss: 1.7993 - acc: 0.2552 - val_loss: 1.7798 - val_acc: 0.2569\n",
      "\n",
      "Epoch 00004: saving model to Model.04-0.2569.hdf5\n",
      "Epoch 5/600\n",
      "251/251 [==============================] - 682s 3s/step - loss: 1.7950 - acc: 0.2591 - val_loss: 1.7770 - val_acc: 0.2558\n",
      "\n",
      "Epoch 00005: saving model to Model.05-0.2558.hdf5\n",
      "Epoch 6/600\n",
      "251/251 [==============================] - 788s 3s/step - loss: 1.7893 - acc: 0.2616 - val_loss: 1.7488 - val_acc: 0.2834\n",
      "\n",
      "Epoch 00006: saving model to Model.06-0.2834.hdf5\n",
      "Epoch 7/600\n",
      "251/251 [==============================] - 823s 3s/step - loss: 1.7811 - acc: 0.2685 - val_loss: 1.7472 - val_acc: 0.2828\n",
      "\n",
      "Epoch 00007: saving model to Model.07-0.2828.hdf5\n",
      "Epoch 8/600\n",
      "251/251 [==============================] - 840s 3s/step - loss: 1.7748 - acc: 0.2750 - val_loss: 1.7365 - val_acc: 0.3096\n",
      "\n",
      "Epoch 00008: saving model to Model.08-0.3096.hdf5\n",
      "Epoch 9/600\n",
      "251/251 [==============================] - 829s 3s/step - loss: 1.7685 - acc: 0.2784 - val_loss: 1.7166 - val_acc: 0.3090\n",
      "\n",
      "Epoch 00009: saving model to Model.09-0.3090.hdf5\n",
      "Epoch 10/600\n",
      "194/251 [======================>.......] - ETA: 2:49 - loss: 1.7630 - acc: 0.2803"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-25-bbc4b43b3082>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     23\u001b[0m                     \u001b[0mnb_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnb_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m                     \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mVal_x\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mVal_y\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m                     callbacks=[checkpointer])\n\u001b[0m",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\keras\\legacy\\interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[0;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[1;32m---> 91\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m   1416\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1417\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1418\u001b[1;33m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[0;32m   1419\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1420\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\keras\\engine\\training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m    215\u001b[0m                 outs = model.train_on_batch(x, y,\n\u001b[0;32m    216\u001b[0m                                             \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 217\u001b[1;33m                                             class_weight=class_weight)\n\u001b[0m\u001b[0;32m    218\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    219\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[1;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[0;32m   1215\u001b[0m             \u001b[0mins\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1216\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1217\u001b[1;33m         \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1218\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0munpack_singleton\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1219\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2713\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2714\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2715\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2716\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2717\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2674\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2675\u001b[1;33m             \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2676\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2677\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1397\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[0;32m   1398\u001b[0m               \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1399\u001b[1;33m               run_metadata_ptr)\n\u001b[0m\u001b[0;32m   1400\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1401\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = model_generate()\n",
    "\n",
    "filepath='Model.{epoch:02d}-{val_acc:.4f}.hdf5'\n",
    "checkpointer = keras.callbacks.ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=False, mode='auto')\n",
    "\n",
    "datagen = ImageDataGenerator(\n",
    "    featurewise_center=False,  # set input mean to 0 over the dataset\n",
    "    samplewise_center=False,  # set each sample mean to 0\n",
    "    featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
    "    samplewise_std_normalization=False,  # divide each input by its std\n",
    "    zca_whitening=False,  # apply ZCA whitening\n",
    "    rotation_range=40,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "    width_shift_range=0.2,  # randomly shift images horizontally (fraction of total width)\n",
    "    height_shift_range=0.2,  # randomly shift images vertically (fraction of total height)\n",
    "    horizontal_flip=True,  # randomly flip images\n",
    "    vertical_flip=False)  # randomly flip images\n",
    "\n",
    "datagen.fit(Train_x)\n",
    "\n",
    "model.fit_generator(datagen.flow(Train_x, Train_y,\n",
    "                    batch_size=batch_size),\n",
    "                    samples_per_epoch=Train_x.shape[0],\n",
    "                    nb_epoch=nb_epoch,\n",
    "                    validation_data=(Val_x, Val_y),\n",
    "                    callbacks=[checkpointer])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
